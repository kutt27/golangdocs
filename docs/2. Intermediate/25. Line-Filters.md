

# Line Filters in Go: A Comprehensive Guide

## Introduction to Line Filters
A line filter is a program that reads input line by line, processes each line according to some rules, and then outputs the result. This pattern is fundamental in Unix/Linux command-line tools like `grep`, `sed`, `awk`, and `sort`. In Go, we can build efficient line filters using the `bufio` package for line-oriented input and output.

## Basic Line Filter Structure

### 1. Simple Line Filter
```go
package main

import (
	"bufio"
	"fmt"
	"os"
)

func main() {
	// Create a new scanner that reads from standard input
	scanner := bufio.NewScanner(os.Stdin)
	
	// Read line by line
	for scanner.Scan() {
		line := scanner.Text()
		// Process the line (in this case, just print it)
		fmt.Println(line)
	}
	
	// Check for any errors during scanning
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error reading input: %v\n", err)
		os.Exit(1)
	}
}
```

### 2. Line Filter with Transformation
```go
func main() {
	scanner := bufio.NewScanner(os.Stdin)
	
	for scanner.Scan() {
		line := scanner.Text()
		// Transform the line to uppercase
		transformed := strings.ToUpper(line)
		fmt.Println(transformed)
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

## Building Practical Line Filters

### 1. Grep-like Filter
```go
func main() {
	if len(os.Args) < 2 {
		fmt.Fprintf(os.Stderr, "Usage: %s <pattern>\n", os.Args[0])
		os.Exit(1)
	}
	
	pattern := os.Args[1]
	scanner := bufio.NewScanner(os.Stdin)
	
	for scanner.Scan() {
		line := scanner.Text()
		// Check if line contains the pattern
		if strings.Contains(line, pattern) {
			fmt.Println(line)
		}
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

### 2. Numbering Lines (like `cat -n`)
```go
func main() {
	scanner := bufio.NewScanner(os.Stdin)
	lineNumber := 1
	
	for scanner.Scan() {
		line := scanner.Text()
		// Print line number followed by the line
		fmt.Printf("%6d  %s\n", lineNumber, line)
		lineNumber++
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

### 3. Unique Lines (like `uniq`)
```go
func main() {
	scanner := bufio.NewScanner(os.Stdin)
	var previousLine string
	
	for scanner.Scan() {
		line := scanner.Text()
		// Only print if different from previous line
		if line != previousLine {
			fmt.Println(line)
			previousLine = line
		}
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

## Advanced Line Filters

### 1. Multiple Pattern Matching
```go
func main() {
	if len(os.Args) < 3 {
		fmt.Fprintf(os.Stderr, "Usage: %s <mode> <pattern1> [pattern2 ...]\n", os.Args[0])
		fmt.Fprintf(os.Stderr, "Modes: any, all, none\n")
		os.Exit(1)
	}
	
	mode := os.Args[1]
	patterns := os.Args[2:]
	
	scanner := bufio.NewScanner(os.Stdin)
	
	for scanner.Scan() {
		line := scanner.Text()
		var matches int
		
		for _, pattern := range patterns {
			if strings.Contains(line, pattern) {
				matches++
			}
		}
		
		// Check based on mode
		printLine := false
		switch mode {
		case "any":
			printLine = matches > 0
		case "all":
			printLine = matches == len(patterns)
		case "none":
			printLine = matches == 0
		}
		
		if printLine {
			fmt.Println(line)
		}
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

### 2. Field Processing (like `awk`)
```go
func main() {
	if len(os.Args) < 3 {
		fmt.Fprintf(os.Stderr, "Usage: %s <field> <delimiter>\n", os.Args[0])
		os.Exit(1)
	}
	
	fieldNum, err := strconv.Atoi(os.Args[1])
	if err != nil {
		fmt.Fprintf(os.Stderr, "Invalid field number: %v\n", err)
		os.Exit(1)
	}
	
	delimiter := os.Args[2]
	scanner := bufio.NewScanner(os.Stdin)
	
	for scanner.Scan() {
		line := scanner.Text()
		fields := strings.Split(line, delimiter)
		
		if fieldNum <= len(fields) {
			fmt.Println(fields[fieldNum-1])
		}
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

### 3. Case-Insensitive Filtering
```go
func main() {
	if len(os.Args) < 2 {
		fmt.Fprintf(os.Stderr, "Usage: %s <pattern>\n", os.Args[0])
		os.Exit(1)
	}
	
	pattern := strings.ToLower(os.Args[1])
	scanner := bufio.NewScanner(os.Stdin)
	
	for scanner.Scan() {
		line := scanner.Text()
		// Case-insensitive comparison
		if strings.Contains(strings.ToLower(line), pattern) {
			fmt.Println(line)
		}
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error: %v\n", err)
		os.Exit(1)
	}
}
```

## Line Filters with Files

### 1. Reading from Files
```go
func main() {
	if len(os.Args) < 2 {
		fmt.Fprintf(os.Stderr, "Usage: %s <filename> [pattern]\n", os.Args[0])
		os.Exit(1)
	}
	
	filename := os.Args[1]
	var pattern string
	if len(os.Args) > 2 {
		pattern = os.Args[2]
	}
	
	// Open the file
	file, err := os.Open(filename)
	if err != nil {
		fmt.Fprintf(os.Stderr, "Error opening file: %v\n", err)
		os.Exit(1)
	}
	defer file.Close()
	
	// Create scanner from file
	scanner := bufio.NewScanner(file)
	
	for scanner.Scan() {
		line := scanner.Text()
		if pattern == "" || strings.Contains(line, pattern) {
			fmt.Println(line)
		}
	}
	
	if err := scanner.Err(); err != nil {
		fmt.Fprintf(os.Stderr, "Error reading file: %v\n", err)
		os.Exit(1)
	}
}
```

### 2. Multiple Files Processing
```go
func processFile(filename string, pattern string) error {
	file, err := os.Open(filename)
	if err != nil {
		return err
	}
	defer file.Close()
	
	scanner := bufio.NewScanner(file)
	
	for scanner.Scan() {
		line := scanner.Text()
		if pattern == "" || strings.Contains(line, pattern) {
			// Print filename prefix for multiple files
			if len(os.Args) > 3 {
				fmt.Printf("%s:%s\n", filename, line)
			} else {
				fmt.Println(line)
			}
		}
	}
	
	return scanner.Err()
}

func main() {
	if len(os.Args) < 2 {
		fmt.Fprintf(os.Stderr, "Usage: %s <file1> [file2 ...] [pattern]\n", os.Args[0])
		os.Exit(1)
	}
	
	// Determine which arguments are files and which is the pattern
	var files []string
	var pattern string
	
	// If last argument doesn't exist as a file, it's the pattern
	lastArg := os.Args[len(os.Args)-1]
	if _, err := os.Stat(lastArg); os.IsNotExist(err) && len(os.Args) > 2 {
		pattern = lastArg
		files = os.Args[1 : len(os.Args)-1]
	} else {
		files = os.Args[1:]
	}
	
	// Process each file
	for _, filename := range files {
		err := processFile(filename, pattern)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Error processing %s: %v\n", filename, err)
		}
	}
}
```

## Real-World Example: Log Analyzer

Let's build a comprehensive log analyzer that demonstrates various line filter techniques:

```go
package main

import (
	"bufio"
	"fmt"
	"os"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"
)

// LogEntry represents a parsed log entry
type LogEntry struct {
	Timestamp time.Time
	Level     string
	Message   string
	Source    string
}

// LogAnalyzer provides log analysis functionality
type LogAnalyzer struct {
	patterns    map[string]*regexp.Regexp
	levelFilter string
	sourceFilter string
	timeStart   time.Time
	timeEnd     time.Time
	unique     bool
	count      bool
	statistics  map[string]int
}

// NewLogAnalyzer creates a new log analyzer
func NewLogAnalyzer() *LogAnalyzer {
	return &LogAnalyzer{
		patterns:   make(map[string]*regexp.Regexp),
		statistics: make(map[string]int),
	}
}

// AddPattern adds a regex pattern to match
func (la *LogAnalyzer) AddPattern(name, pattern string) error {
	re, err := regexp.Compile(pattern)
	if err != nil {
		return fmt.Errorf("invalid pattern %q: %w", name, err)
	}
	la.patterns[name] = re
	return nil
}

// SetLevelFilter sets the log level filter
func (la *LogAnalyzer) SetLevelFilter(level string) {
	la.levelFilter = strings.ToUpper(level)
}

// SetSourceFilter sets the source filter
func (la *LogAnalyzer) SetSourceFilter(source string) {
	la.sourceFilter = source
}

// SetTimeRange sets the time range filter
func (la *LogAnalyzer) SetTimeRange(start, end string) error {
	var err error
	if start != "" {
		la.timeStart, err = time.Parse("2006-01-02", start)
		if err != nil {
			return fmt.Errorf("invalid start time: %w", err)
		}
	}
	if end != "" {
		la.timeEnd, err = time.Parse("2006-01-02", end)
		if err != nil {
			return fmt.Errorf("invalid end time: %w", err)
		}
	}
	return nil
}

// SetUnique enables unique line filtering
func (la *LogAnalyzer) SetUnique(unique bool) {
	la.unique = unique
}

// SetCount enables counting mode
func (la *LogAnalyzer) SetCount(count bool) {
	la.count = count
}

// ParseLogLine parses a log line into a LogEntry
func (la *LogAnalyzer) ParseLogLine(line string) (*LogEntry, error) {
	// Simple log format: [timestamp] [level] [source] message
	// Example: [2023-11-15T14:30:45Z] [ERROR] [server] Database connection failed
	
	parts := strings.SplitN(line, "]", 3)
	if len(parts) < 3 {
		return nil, fmt.Errorf("invalid log format")
	}
	
	// Parse timestamp
	timestampStr := strings.Trim(parts[0], "[ ")
	timestamp, err := time.Parse(time.RFC3339, timestampStr)
	if err != nil {
		return nil, fmt.Errorf("invalid timestamp: %w", err)
	}
	
	// Parse level
	levelStr := strings.Trim(parts[1], "[ ")
	level := strings.ToUpper(levelStr)
	
	// Parse source and message
	rest := strings.TrimSpace(parts[2])
	sourceEnd := strings.Index(rest, "]")
	if sourceEnd == -1 {
		return nil, fmt.Errorf("invalid source format")
	}
	
	source := strings.Trim(rest[:sourceEnd], "[ ")
	message := strings.TrimSpace(rest[sourceEnd+1:])
	
	return &LogEntry{
		Timestamp: timestamp,
		Level:     level,
		Message:   message,
		Source:    source,
	}, nil
}

// ShouldInclude determines if a log entry should be included
func (la *LogAnalyzer) ShouldInclude(entry *LogEntry) bool {
	// Level filter
	if la.levelFilter != "" && entry.Level != la.levelFilter {
		return false
	}
	
	// Source filter
	if la.sourceFilter != "" && entry.Source != la.sourceFilter {
		return false
	}
	
	// Time range filter
	if !la.timeStart.IsZero() && entry.Timestamp.Before(la.timeStart) {
		return false
	}
	if !la.timeEnd.IsZero() && entry.Timestamp.After(la.timeEnd) {
		return false
	}
	
	// Pattern matching
	for _, re := range la.patterns {
		if !re.MatchString(entry.Message) {
			return false
		}
	}
	
	return true
}

// ProcessFile processes a log file
func (la *LogAnalyzer) ProcessFile(filename string) error {
	file, err := os.Open(filename)
	if err != nil {
		return fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()
	
	scanner := bufio.NewScanner(file)
	var previousLine string
	
	for scanner.Scan() {
		line := scanner.Text()
		
		// Parse log entry
		entry, err := la.ParseLogLine(line)
		if err != nil {
			// If parsing fails, treat as plain text
			entry = &LogEntry{
				Message: line,
			}
		}
		
		// Check filters
		if !la.ShouldInclude(entry) {
			continue
		}
		
		// Update statistics
		la.statistics[entry.Level]++
		
		// Unique filter
		if la.unique && line == previousLine {
			continue
		}
		
		// Output the line
		if la.count {
			// Count mode - we'll output statistics at the end
		} else {
			fmt.Println(line)
		}
		
		previousLine = line
	}
	
	return scanner.Err()
}

// PrintStatistics prints the collected statistics
func (la *LogAnalyzer) PrintStatistics() {
	if !la.count {
		return
	}
	
	fmt.Println("\n=== Log Statistics ===")
	
	// Sort levels by count
	type levelCount struct {
		level string
		count int
	}
	
	var counts []levelCount
	for level, count := range la.statistics {
		counts = append(counts, levelCount{level, count})
	}
	
	sort.Slice(counts, func(i, j int) bool {
		return counts[i].count > counts[j].count
	})
	
	total := 0
	for _, lc := range counts {
		total += lc.count
	}
	
	for _, lc := range counts {
		percentage := float64(lc.count) / float64(total) * 100
		fmt.Printf("%-8s: %6d (%5.1f%%)\n", lc.level, lc.count, percentage)
	}
	
	fmt.Printf("Total: %d entries\n", total)
}

func main() {
	analyzer := NewLogAnalyzer()
	
	// Parse command line arguments
	args := os.Args[1:]
	i := 0
	
	for i < len(args) {
		switch args[i] {
		case "-p", "--pattern":
			if i+1 >= len(args) {
				fmt.Fprintln(os.Stderr, "Error: pattern name required")
				os.Exit(1)
			}
			name := args[i+1]
			if i+2 >= len(args) {
				fmt.Fprintln(os.Stderr, "Error: pattern required")
				os.Exit(1)
			}
			pattern := args[i+2]
			if err := analyzer.AddPattern(name, pattern); err != nil {
				fmt.Fprintf(os.Stderr, "Error: %v\n", err)
				os.Exit(1)
			}
			i += 3
			
		case "-l", "--level":
			if i+1 >= len(args) {
				fmt.Fprintln(os.Stderr, "Error: level required")
				os.Exit(1)
			}
			analyzer.SetLevelFilter(args[i+1])
			i += 2
			
		case "-s", "--source":
			if i+1 >= len(args) {
				fmt.Fprintln(os.Stderr, "Error: source required")
				os.Exit(1)
			}
			analyzer.SetSourceFilter(args[i+1])
			i += 2
			
		case "-t", "--time":
			if i+2 >= len(args) {
				fmt.Fprintln(os.Stderr, "Error: start and end time required")
				os.Exit(1)
			}
			if err := analyzer.SetTimeRange(args[i+1], args[i+2]); err != nil {
				fmt.Fprintf(os.Stderr, "Error: %v\n", err)
				os.Exit(1)
			}
			i += 3
			
		case "-u", "--unique":
			analyzer.SetUnique(true)
			i++
			
		case "-c", "--count":
			analyzer.SetCount(true)
			i++
			
		default:
			// Assume it's a filename
			filename := args[i]
			if err := analyzer.ProcessFile(filename); err != nil {
				fmt.Fprintf(os.Stderr, "Error processing %s: %v\n", filename, err)
				os.Exit(1)
			}
			i++
		}
	}
	
	// Print statistics if in count mode
	analyzer.PrintStatistics()
}
```

### How This Example Works:

1. **Log Parsing**:
   - Parses structured log entries with timestamp, level, source, and message
   - Handles both structured and unstructured log lines
   - Supports multiple log formats through extensibility

2. **Filtering Capabilities**:
   - Level-based filtering (ERROR, WARNING, INFO, etc.)
   - Source-based filtering (specific modules or services)
   - Time range filtering
   - Pattern matching with regular expressions
   - Duplicate line removal

3. **Analysis Features**:
   - Statistics collection and reporting
   - Count mode for aggregate analysis
   - Percentage calculations for log levels

4. **Command-Line Interface**:
   - Flexible argument parsing
   - Multiple filter options
   - Support for multiple input files

### Real-World Applications:

1. **Log Analysis**:
   - Filter application logs by error level
   - Find specific error patterns
   - Analyze log frequency over time
   - Identify problematic modules

2. **System Administration**:
   - Monitor system logs for specific events
   - Filter authentication logs
   - Track resource usage patterns
   - Generate usage reports

3. **Security Monitoring**:
   - Detect suspicious activity patterns
   - Filter access logs for specific IPs
   - Monitor authentication failures
   - Generate security reports

## Best Practices

### 1. Handle Large Files Efficiently
```go
// Good: Process line by line without loading entire file
func processLargeFile(filename string) error {
	file, err := os.Open(filename)
	if err != nil {
		return err
	}
	defer file.Close()
	
	scanner := bufio.NewScanner(file)
	// Adjust buffer size for large files
	buf := make([]byte, 64*1024) // 64KB buffer
	scanner.Buffer(buf, 1024*1024) // Max token size 1MB
	
	for scanner.Scan() {
		// Process line
	}
	return scanner.Err()
}

// Bad: Read entire file into memory
func processLargeFileBad(filename string) error {
	data, err := os.ReadFile(filename)
	if err != nil {
		return err
	}
	lines := strings.Split(string(data), "\n")
	for _, line := range lines {
		// Process line
	}
	return nil
}
```

### 2. Use Appropriate Scanner Settings
```go
// Good: Configure scanner for your use case
func createScanner(file *os.File) *bufio.Scanner {
	scanner := bufio.NewScanner(file)
	
	// Adjust buffer size based on expected line length
	scanner.Buffer(make([]byte, 4096), 1024*1024)
	
	// Custom split function if needed
	scanner.Split(bufio.ScanLines)
	
	return scanner
}

// Bad: Use default scanner for all cases
func createScannerBad(file *os.File) *bufio.Scanner {
	return bufio.NewScanner(file) // May not be optimal
}
```

### 3. Graceful Error Handling
```go
// Good: Handle errors gracefully and continue processing
func processFilesWithErrors(filenames []string) {
	for _, filename := range filenames {
		file, err := os.Open(filename)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Warning: Cannot open %s: %v\n", filename, err)
			continue
		}
		
		scanner := bufio.NewScanner(file)
		for scanner.Scan() {
			// Process line
		}
		
		if err := scanner.Err(); err != nil {
			fmt.Fprintf(os.Stderr, "Warning: Error reading %s: %v\n", filename, err)
		}
		
		file.Close()
	}
}

// Bad: Exit on first error
func processFilesWithErrorsBad(filenames []string) {
	for _, filename := range filenames {
		file, err := os.Open(filename)
		if err != nil {
			fmt.Fprintf(os.Stderr, "Error: %v\n", err)
			os.Exit(1)
		}
		// Process file...
	}
}
```

### 4. Support Multiple Input Sources
```go
// Good: Handle both files and stdin
func processInput(input string) error {
	var scanner *bufio.Scanner
	
	if input == "-" || input == "" {
		// Read from stdin
		scanner = bufio.NewScanner(os.Stdin)
	} else {
		// Read from file
		file, err := os.Open(input)
		if err != nil {
			return err
		}
		defer file.Close()
		scanner = bufio.NewScanner(file)
	}
	
	for scanner.Scan() {
		// Process line
	}
	
	return scanner.Err()
}

// Bad: Only handle files
func processInputBad(input string) error {
	file, err := os.Open(input)
	if err != nil {
		return err
	}
	defer file.Close()
	
	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		// Process line
	}
	return scanner.Err()
}
```

## Performance Considerations

### 1. Buffer Size Optimization
```go
// Benchmark different buffer sizes
func benchmarkBufferSize(filename string, bufferSize int) time.Duration {
	file, err := os.Open(filename)
	if err != nil {
		return 0
	}
	defer file.Close()
	
	scanner := bufio.NewScanner(file)
	buf := make([]byte, bufferSize)
	scanner.Buffer(buf, bufferSize)
	
	start := time.Now()
	for scanner.Scan() {
		// Process line
	}
	return time.Since(start)
}
```

### 2. Parallel Processing for Multiple Files
```go
func processFilesParallel(filenames []string) {
	var wg sync.WaitGroup
	results := make(chan string, len(filenames))
	
	for _, filename := range filenames {
		wg.Add(1)
		go func(fname string) {
			defer wg.Done()
			
			file, err := os.Open(fname)
			if err != nil {
				results <- fmt.Sprintf("Error opening %s: %v", fname, err)
				return
			}
			defer file.Close()
			
			scanner := bufio.NewScanner(file)
			lineCount := 0
			for scanner.Scan() {
				lineCount++
			}
			
			results <- fmt.Sprintf("%s: %d lines", fname, lineCount)
		}(filename)
	}
	
	// Wait for all goroutines to complete
	go func() {
		wg.Wait()
		close(results)
	}()
	
	// Collect results
	for result := range results {
		fmt.Println(result)
	}
}
```

## Conclusion

Line filters are a powerful and flexible pattern in Go for processing text input line by line. The `bufio` package provides excellent tools for building efficient line filters that can:

1. **Process Text Efficiently**:
   - Handle large files without loading everything into memory
   - Process input line by line with minimal memory overhead
   - Support both files and standard input

2. **Filter and Transform**:
   - Filter lines based on patterns, levels, or other criteria
   - Transform lines with string operations
   - Combine multiple filters for complex processing

3. **Analyze and Aggregate**:
   - Collect statistics and metrics
   - Count occurrences and frequencies
   - Generate reports and summaries

4. **Integrate with Unix Tools**:
   - Work seamlessly in Unix pipelines
   - Support standard input/output streams
   - Follow Unix philosophy of doing one thing well

The log analyzer example demonstrates how to build a sophisticated line filter that combines multiple filtering techniques, pattern matching, and statistical analysis. By following best practices and understanding performance considerations, you can create efficient and reliable line filters for various text processing tasks in Go.

Key takeaways:
1. **Use `bufio.Scanner`** for line-oriented input processing
2. **Handle large files** by processing line by line
3. **Support multiple input sources** (files and stdin)
4. **Provide flexible filtering** options through command-line arguments
5. **Handle errors gracefully** without terminating the entire process
6. **Consider performance** when dealing with very large files

Line filters are a fundamental tool in text processing and system administration. With Go's excellent I/O libraries and the patterns shown in this guide, you can build powerful and efficient line filters for your specific needs.