# Strings and Runes in Go: A Comprehensive Guide

## Introduction to Strings in Go
In Go, strings are immutable sequences of bytes. Unlike many other languages, Go strings are UTF-8 encoded by default, which makes them particularly powerful for handling international text. However, this also introduces some unique characteristics that every Go developer must understand.

### Basic String Declaration
```go
package main

import "fmt"

func main() {
    // String literals
    s1 := "Hello, World!"
    s2 := `This is a raw string literal
    that can span multiple lines
    and include "quotes" without escaping`
    
    fmt.Println(s1)
    fmt.Println(s2)
}
```

## Strings are Immutable
Once created, strings in Go cannot be modified. Any operation that appears to modify a string actually creates a new one.

```go
func main() {
    s := "hello"
    // s[0] = 'H' // This would cause a compilation error
    
    // To "modify", we create a new string
    s = "H" + s[1:]
    fmt.Println(s) // "Hello"
}
```

## UTF-8 Encoding and Runes
Go strings are UTF-8 encoded, which means:
- Each Unicode character (code point) can be represented by 1 to 4 bytes
- ASCII characters use 1 byte
- Non-Latin characters (like Chinese, Arabic, emojis) use multiple bytes

### What is a Rune?
In Go, a `rune` is an alias for `int32` and represents a single Unicode code point. It's Go's way of handling characters properly.

```go
package main

import (
    "fmt"
    "unicode/utf8"
)

func main() {
    s := "Hello, ä¸–ç•Œ"
    
    // Length in bytes
    fmt.Println("Byte length:", len(s)) // 13
    
    // Length in runes (characters)
    fmt.Println("Rune length:", utf8.RuneCountInString(s)) // 9
    
    // Iterate as runes
    for i, r := range s {
        fmt.Printf("%d: %q (%d bytes)\n", i, r, utf8.RuneLen(r))
    }
}
```

Output:
```
Byte length: 13
Rune length: 9
0: 'H' (1 bytes)
1: 'e' (1 bytes)
2: 'l' (1 bytes)
3: 'l' (1 bytes)
4: 'o' (1 bytes)
5: ',' (1 bytes)
6: ' ' (1 bytes)
7: 'ä¸–' (3 bytes)
10: 'ç•Œ' (3 bytes)
```

## Working with Runes
### Converting Between Strings and Runes
```go
func main() {
    // String to rune slice
    s := "Hello, ä¸–ç•Œ"
    runes := []rune(s)
    fmt.Println(runes) // [72 101 108 108 111 44 32 19990 30028]
    
    // Rune slice to string
    s2 := string(runes)
    fmt.Println(s2) // "Hello, ä¸–ç•Œ"
    
    // Individual rune to string
    r := 'ä¸–'
    s3 := string(r)
    fmt.Println(s3) // "ä¸–"
}
```

### Accessing Individual Characters
```go
func main() {
    s := "Hello, ä¸–ç•Œ"
    
    // WRONG: This would give a byte, not a character
    // fmt.Println(s[7]) // This would print 228 (first byte of 'ä¸–')
    
    // CORRECT: Convert to rune slice first
    runes := []rune(s)
    fmt.Printf("%c\n", runes[7]) // 'ä¸–'
    
    // Or use range
    for i, r := range s {
        if i == 7 {
            fmt.Printf("%c\n", r) // 'ä¸–'
        }
    }
}
```

## Common String Operations

### 1. Concatenation
```go
func main() {
    s1 := "Hello"
    s2 := "World"
    
    // Using + operator
    s3 := s1 + ", " + s2
    fmt.Println(s3) // "Hello, World"
    
    // Using fmt.Sprintf
    s4 := fmt.Sprintf("%s, %s", s1, s2)
    fmt.Println(s4) // "Hello, World"
    
    // Using strings.Builder (efficient for multiple concatenations)
    var builder strings.Builder
    builder.WriteString(s1)
    builder.WriteString(", ")
    builder.WriteString(s2)
    s5 := builder.String()
    fmt.Println(s5) // "Hello, World"
}
```

### 2. Substrings
```go
func main() {
    s := "Hello, ä¸–ç•Œ"
    
    // Get substring by byte indices (DANGEROUS for multi-byte characters)
    sub1 := s[0:5] // "Hello"
    fmt.Println(sub1)
    
    // Safe substring using runes
    runes := []rune(s)
    sub2 := string(runes[7:9]) // "ä¸–ç•Œ"
    fmt.Println(sub2)
}
```

### 3. Searching and Replacing
```go
func main() {
    s := "Hello, ä¸–ç•Œ! Hello, Go!"
    
    // Contains
    fmt.Println(strings.Contains(s, "Hello")) // true
    
    // Index
    fmt.Println(strings.Index(s, "Hello")) // 0
    fmt.Println(strings.Index(s, "ä¸–ç•Œ"))   // 7
    
    // Replace
    s2 := strings.ReplaceAll(s, "Hello", "Hi")
    fmt.Println(s2) // "Hi, ä¸–ç•Œ! Hi, Go!"
    
    // Split
    parts := strings.Split(s, ", ")
    fmt.Println(parts) // ["Hello" "ä¸–ç•Œ! Hello" "Go!"]
}
```

### 4. Trimming and Padding
```go
func main() {
    s := "   Hello, World!   "
    
    // Trim spaces
    trimmed := strings.TrimSpace(s)
    fmt.Println(trimmed) // "Hello, World!"
    
    // Trim specific characters
    s2 := "!!!Hello, World!!!"
    trimmed2 := strings.Trim(s2, "!")
    fmt.Println(trimmed2) // "Hello, World"
    
    // Padding
    padded := fmt.Sprintf("%-20s", "Hello")
    fmt.Printf("'%s'\n", padded) // 'Hello               '
}
```

### 5. Case Conversion
```go
func main() {
    s := "Hello, ä¸–ç•Œ"
    
    // To lower
    lower := strings.ToLower(s)
    fmt.Println(lower) // "hello, ä¸–ç•Œ"
    
    // To upper
    upper := strings.ToUpper(s)
    fmt.Println(upper) // "HELLO, ä¸–ç•Œ"
    
    // To title
    title := strings.ToTitle(s)
    fmt.Println(title) // "HELLO, ä¸–ç•Œ"
}
```

## Real-World Example: Text Processing with Unicode

Let's build a practical text processing utility that:
1. Counts characters (not bytes)
2. Finds unique characters
3. Reverses the string properly
4. Handles emojis and complex scripts

```go
package main

import (
    "fmt"
    "sort"
    "strings"
    "unicode"
    "unicode/utf8"
)

// TextProcessor handles Unicode-aware text operations
type TextProcessor struct {
    text string
}

// NewTextProcessor creates a new processor
func NewTextProcessor(text string) *TextProcessor {
    return &TextProcessor{text: text}
}

// CharacterCount returns the number of characters (runes)
func (tp *TextProcessor) CharacterCount() int {
    return utf8.RuneCountInString(tp.text)
}

// UniqueCharacters returns a sorted slice of unique characters
func (tp *TextProcessor) UniqueCharacters() []rune {
    seen := make(map[rune]bool)
    for _, r := range tp.text {
        seen[r] = true
    }
    
    unique := make([]rune, 0, len(seen))
    for r := range seen {
        unique = append(unique, r)
    }
    
    sort.Slice(unique, func(i, j int) bool {
        return unique[i] < unique[j]
    })
    
    return unique
}

// Reverse returns the string with characters in reverse order
func (tp *TextProcessor) Reverse() string {
    runes := []rune(tp.text)
    for i, j := 0, len(runes)-1; i < j; i, j = i+1, j-1 {
        runes[i], runes[j] = runes[j], runes[i]
    }
    return string(runes)
}

// WordCount returns the number of words (Unicode-aware)
func (tp *TextProcessor) WordCount() int {
    // Simple word count by splitting on whitespace
    words := strings.Fields(tp.text)
    return len(words)
}

// ContainsEmoji checks if the text contains any emoji
func (tp *TextProcessor) ContainsEmoji() bool {
    for _, r := range tp.text {
        // Check if the rune is in the emoji ranges
        if unicode.Is(unicode.So, r) || // Symbols, Other (includes many emojis)
           (r >= 0x1F600 && r <= 0x1F64F) || // Emoticons
           (r >= 0x1F300 && r <= 0x1F5FF) || // Misc Symbols and Pictographs
           (r >= 0x1F680 && r <= 0x1F6FF) || // Transport and Map
           (r >= 0x2600 && r <= 0x26FF) ||   // Misc Symbols
           (r >= 0x2700 && r <= 0x27BF) {    // Dingbats
            return true
        }
    }
    return false
}

// NormalizeSpaces replaces multiple whitespace with single space
func (tp *TextProcessor) NormalizeSpaces() string {
    // Split on whitespace to get words
    words := strings.Fields(tp.text)
    return strings.Join(words, " ")
}

func main() {
    // Test with a complex string containing:
    // - ASCII characters
    // - Chinese characters
    // - Emojis
    // - Multiple spaces
    text := "Hello ä¸–ç•Œ! ðŸŒ Go is awesome!   ðŸ˜Š"
    
    processor := NewTextProcessor(text)
    
    fmt.Println("Original text:", text)
    fmt.Println("Byte length:", len(text))
    fmt.Println("Character count:", processor.CharacterCount())
    fmt.Println("Word count:", processor.WordCount())
    fmt.Println("Contains emoji:", processor.ContainsEmoji())
    
    fmt.Println("\nUnique characters:")
    for _, r := range processor.UniqueCharacters() {
        fmt.Printf("%q ", r)
    }
    
    fmt.Println("\n\nReversed text:", processor.Reverse())
    
    normalized := processor.NormalizeSpaces()
    fmt.Println("\nNormalized text:", normalized)
    
    // Demonstrate the difference between byte and rune operations
    fmt.Println("\n--- Byte vs Rune Operations ---")
    fmt.Println("First 5 bytes:", text[:5]) // "Hello"
    fmt.Println("First 5 runes:", string([]rune(text)[:5])) // "Hello ä¸–"
}
```

### Output:
```
Original text: Hello ä¸–ç•Œ! ðŸŒ Go is awesome!   ðŸ˜Š
Byte length: 39
Character count: 23
Word count: 6
Contains emoji: true

Unique characters:
' ' '!' 'G' 'H' 'a' 'e' 'h' 'i' 'l' 'm' 'o' 's' 'v' 'w' 'ä¸–' 'ðŸ˜Š' 'ðŸŒ' 

Reversed text: ðŸ˜Š   !emosewa si oG ðŸŒ !ç•Œä¸– olleH

Normalized text: Hello ä¸–ç•Œ! ðŸŒ Go is awesome! ðŸ˜Š

--- Byte vs Rune Operations ---
First 5 bytes: Hello
First 5 runes: Hello ä¸–
```

### How This Example Demonstrates Key Concepts:

1. **Unicode Awareness**:
   - Correctly counts characters (23) rather than bytes (39)
   - Properly handles multi-byte characters like Chinese and emojis
   - Reverses the string by characters, not bytes

2. **Rune Processing**:
   - Uses `[]rune` conversion for character-level operations
   - Implements Unicode-aware word counting
   - Detects emojis by checking Unicode ranges

3. **String Immutability**:
   - All operations return new strings rather than modifying the original
   - Uses `strings.Builder` for efficient concatenation (in the full implementation)

4. **Real-World Text Processing**:
   - Normalizes whitespace (common in text cleaning)
   - Identifies unique characters (useful for analysis)
   - Demonstrates safe substring operations

### Real-World Applications of This Pattern:

1. **Text Analysis Tools**:
   - Character frequency analysis
   - Language detection
   - Text normalization for NLP

2. **Content Processing Systems**:
   - Blog post processors that handle international text
   - Social media content analyzers
   - Chat systems that need to process emojis

3. **Data Validation**:
   - Input sanitization for web forms
   - Password strength checkers that handle Unicode
   - Username validation systems

4. **Localization Tools**:
   - Translation systems that preserve character counts
   - Text fitting algorithms for UI elements
   - Right-to-left text processing

### Benefits of This Approach:

1. **Correctness**:
   - Properly handles all Unicode characters
   - Avoids common pitfalls with multi-byte characters
   - Produces accurate results for international text

2. **Efficiency**:
   - Uses `strings.Builder` for efficient concatenation
   - Minimizes allocations where possible
   - Processes text in a single pass when feasible

3. **Maintainability**:
   - Encapsulates text processing logic
   - Provides clear, reusable methods
   - Separates concerns for different operations

## Conclusion

Understanding strings and runes in Go is essential for:
1. **Internationalization**: Building applications that work with all languages
2. **Text Processing**: Correctly manipulating user input and content
3. **Data Validation**: Ensuring proper handling of all character types
4. **Performance**: Writing efficient string operations

Key takeaways:
1. Go strings are UTF-8 encoded sequences of bytes
2. Use `rune` (`int32`) to represent Unicode code points
3. Always prefer `range` or `[]rune` conversion for character-level operations
4. Be aware of the difference between byte length and character count
5. Use the `strings` and `unicode` packages for common operations

The text processing example demonstrates how to build robust, Unicode-aware applications in Go. By properly handling runes and understanding UTF-8 encoding, you can create applications that work seamlessly with text from any language, including emojis and complex scripts.

Mastering strings and runes is fundamental to writing effective Go applications, especially those that process user input, handle internationalization, or work with text data. This knowledge will help you avoid common pitfalls and build more reliable, global-ready software.