# Text Embeddings in Go: A Comprehensive Guide

## Introduction to Text Embeddings
Text embeddings are numerical representations of text data that capture semantic meaning. They transform words, sentences, or documents into dense vectors (arrays of numbers) where similar texts have similar vector representations. This enables machines to understand and process human language in a mathematical way.

In Go, while we don't have native NLP capabilities like Python, we can leverage external APIs, pre-trained models, and specialized libraries to work with text embeddings effectively.

## Why Use Text Embeddings?
1. **Semantic Search**: Find documents based on meaning rather than keywords
2. **Similarity Comparison**: Measure how similar two texts are
3. **Classification**: Categorize text based on content
4. **Clustering**: Group similar documents together
5. **Recommendation Systems**: Suggest similar content
6. **Anomaly Detection**: Identify unusual text patterns

## Key Concepts

### 1. Vector Representation
Text is converted into fixed-length vectors (typically 384, 768, or 1536 dimensions):
```go
type Embedding []float32

func (e Embedding) Dimensions() int {
    return len(e)
}
```

### 2. Similarity Metrics
Common ways to measure similarity between embeddings:
- **Cosine Similarity**: Measures angle between vectors (most common)
- **Euclidean Distance**: Measures straight-line distance
- **Dot Product**: Measures alignment of vectors

```go
// Cosine similarity between two embeddings
func CosineSimilarity(a, b Embedding) float64 {
    if len(a) != len(b) {
        panic("Embeddings must have same dimensions")
    }
    
    var dotProduct, normA, normB float64
    
    for i := range a {
        dotProduct += float64(a[i]) * float64(b[i])
        normA += float64(a[i]) * float64(a[i])
        normB += float64(b[i]) * float64(b[i])
    }
    
    if normA == 0 || normB == 0 {
        return 0
    }
    
    return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}
```

## Approaches to Generate Embeddings in Go

### 1. Using External APIs (Recommended)
Services like OpenAI, Cohere, and Hugging Face provide embedding APIs:

```go
package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
)

// OpenAIEmbeddingRequest represents the request to OpenAI's embedding API
type OpenAIEmbeddingRequest struct {
	Input          string `json:"input"`
	Model          string `json:"model"`
	EncodingFormat string `json:"encoding_format,omitempty"`
}

// OpenAIEmbeddingResponse represents the response from OpenAI's embedding API
type OpenAIEmbeddingResponse struct {
	Data []struct {
		Embedding []float32 `json:"embedding"`
	} `json:"data"`
}

// GenerateEmbeddingUsingOpenAI generates an embedding using OpenAI's API
func GenerateEmbeddingUsingOpenAI(text, apiKey string) ([]float32, error) {
	reqBody := OpenAIEmbeddingRequest{
		Input: text,
		Model: "text-embedding-ada-002",
	}
	
	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %v", err)
	}
	
	req, err := http.NewRequest("POST", "https://api.openai.com/v1/embeddings", bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %v", err)
	}
	
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+apiKey)
	
	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to send request: %v", err)
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("API request failed with status %d: %s", resp.StatusCode, string(body))
	}
	
	var result OpenAIEmbeddingResponse
	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, fmt.Errorf("failed to decode response: %v", err)
	}
	
	if len(result.Data) == 0 {
		return nil, fmt.Errorf("no embeddings returned")
	}
	
	return result.Data[0].Embedding, nil
}

func main() {
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		fmt.Println("Please set OPENAI_API_KEY environment variable")
		return
	}
	
	text := "Go is a statically typed, compiled programming language"
	embedding, err := GenerateEmbeddingUsingOpenAI(text, apiKey)
	if err != nil {
		fmt.Printf("Error generating embedding: %v\n", err)
		return
	}
	
	fmt.Printf("Generated embedding with %d dimensions\n", len(embedding))
	fmt.Printf("First 5 dimensions: %v\n", embedding[:5])
}
```

### 2. Using Pre-trained Models with ONNX
For local processing without API calls:

```go
package main

import (
	"fmt"
	"ort"
)

// LoadSentenceTransformer loads a pre-trained sentence transformer model
func LoadSentenceTransformer(modelPath string) (*ort.Session, error) {
	return ort.NewSession(modelPath, nil)
}

// GenerateEmbeddingWithONNX generates embedding using ONNX model
func GenerateEmbeddingWithONNX(session *ort.Session, text string) ([]float32, error) {
	// Tokenization would happen here (simplified for example)
	// In practice, you'd need a tokenizer compatible with your model
	
	// Create input tensor (simplified)
	inputShape := []int64{1, 1} // Batch size 1, sequence length 1
	inputData := []int32{123}    // Example token ID
	
	inputTensor, err := ort.NewTensor(ort.TensorTypeINT32, inputShape, inputData)
	if err != nil {
		return nil, fmt.Errorf("failed to create input tensor: %v", err)
	}
	defer inputTensor.Release()
	
	// Run inference
	output, err := session.Run(map[string]ort.Value{"input_ids": inputTensor})
	if err != nil {
		return nil, fmt.Errorf("inference failed: %v", err)
	}
	defer output.Release()
	
	// Extract embedding (simplified)
	embeddingTensor := output["last_hidden_state"].(*ort.Tensor)
	embedding := embeddingTensor.GetData().([]float32)
	
	return embedding, nil
}

func main() {
	// This example requires the ONNX Runtime for Go and a pre-trained model
	// In practice, you'd download a model like all-MiniLM-L6-v2.onnx
	
	fmt.Println("ONNX-based embedding generation requires additional setup")
	fmt.Println("See: https://github.com/microsoft/onnxruntime")
}
```

### 3. Using Go-specific Libraries
Some Go libraries provide embedding capabilities:

```go
package main

import (
	"fmt"
	"github.com/kniren/gota/dataframe"
	"github.com/sjwhitworth/golearn/base"
	"github.com/sjwhitworth/golearn/knn"
)

// Simple example using golearn for text classification
// Note: This is a simplified example - real embedding generation would require more setup
func main() {
	// Load dataset (in practice, you'd use a text dataset)
	rawData, err := base.ParseCSVToInstances("text_data.csv", true)
	if err != nil {
		panic(err)
	}
	
	// Create a kNN classifier
	cls := knn.NewKnnClassifier("euclidean", "linear", 2)
	cls.Fit(rawData)
	
	// Make predictions (simplified)
	fmt.Println("Text classification with golearn")
	fmt.Println("This example requires proper text preprocessing")
}
```

## Real-World Example: Semantic Search Engine

Let's build a complete semantic search system that:
1. Pre-computes embeddings for a document collection
2. Stores embeddings in a vector database
3. Searches for similar documents based on query meaning

```go
package main

import (
	"encoding/json"
	"fmt"
	"log"
	"math"
	"os"
	"sort"
	"sync"
	"time"
)

// Document represents a text document with its embedding
type Document struct {
	ID        string
	Title     string
	Content   string
	Embedding []float32
	Timestamp time.Time
}

// SearchResult represents a search result with similarity score
type SearchResult struct {
	Document   Document
	Similarity float64
}

// VectorDatabase stores and searches embeddings
type VectorDatabase struct {
	documents []Document
	mu        sync.RWMutex
}

func NewVectorDatabase() *VectorDatabase {
	return &VectorDatabase{
		documents: make([]Document, 0),
	}
}

// AddDocument adds a document to the database
func (db *VectorDatabase) AddDocument(doc Document) {
	db.mu.Lock()
	defer db.mu.Unlock()
	db.documents = append(db.documents, doc)
}

// Search finds similar documents based on embedding similarity
func (db *VectorDatabase) Search(queryEmbedding []float32, limit int) []SearchResult {
	db.mu.RLock()
	defer db.mu.RUnlock()
	
	var results []SearchResult
	
	for _, doc := range db.documents {
		similarity := CosineSimilarity(queryEmbedding, doc.Embedding)
		results = append(results, SearchResult{
			Document:   doc,
			Similarity: similarity,
		})
	}
	
	// Sort by similarity (descending)
	sort.Slice(results, func(i, j int) bool {
		return results[i].Similarity > results[j].Similarity
	})
	
	if len(results) > limit {
		results = results[:limit]
	}
	
	return results
}

// SemanticSearchEngine handles the complete search workflow
type SemanticSearchEngine struct {
	db         *VectorDatabase
	apiKey     string
	embeddingCache map[string][]float32
	cacheMu    sync.RWMutex
}

func NewSemanticSearchEngine(apiKey string) *SemanticSearchEngine {
	return &SemanticSearchEngine{
		db:         NewVectorDatabase(),
		apiKey:     apiKey,
		embeddingCache: make(map[string][]float32),
	}
}

// IndexDocument generates embedding and adds to database
func (se *SemanticSearchEngine) IndexDocument(id, title, content string) error {
	// Check cache first
	se.cacheMu.RLock()
	if embedding, exists := se.embeddingCache[content]; exists {
		se.cacheMu.RUnlock()
		doc := Document{
			ID:        id,
			Title:     title,
			Content:   content,
			Embedding: embedding,
			Timestamp: time.Now(),
		}
		se.db.AddDocument(doc)
		return nil
	}
	se.cacheMu.RUnlock()
	
	// Generate embedding
	embedding, err := GenerateEmbeddingUsingOpenAI(content, se.apiKey)
	if err != nil {
		return fmt.Errorf("failed to generate embedding: %v", err)
	}
	
	// Cache the embedding
	se.cacheMu.Lock()
	se.embeddingCache[content] = embedding
	se.cacheMu.Unlock()
	
	// Add to database
	doc := Document{
		ID:        id,
		Title:     title,
		Content:   content,
		Embedding: embedding,
		Timestamp: time.Now(),
	}
	se.db.AddDocument(doc)
	
	return nil
}

// Search performs semantic search
func (se *SemanticSearchEngine) Search(query string, limit int) ([]SearchResult, error) {
	// Generate query embedding
	queryEmbedding, err := GenerateEmbeddingUsingOpenAI(query, se.apiKey)
	if err != nil {
		return nil, fmt.Errorf("failed to generate query embedding: %v", err)
	}
	
	// Search database
	return se.db.Search(queryEmbedding, limit), nil
}

// SaveDatabase saves the database to a file
func (se *SemanticSearchEngine) SaveDatabase(filename string) error {
	se.db.mu.RLock()
	defer se.db.mu.RUnlock()
	
	file, err := os.Create(filename)
	if err != nil {
		return err
	}
	defer file.Close()
	
	encoder := json.NewEncoder(file)
	return encoder.Encode(se.db.documents)
}

// LoadDatabase loads the database from a file
func (se *SemanticSearchEngine) LoadDatabase(filename string) error {
	file, err := os.Open(filename)
	if err != nil {
		return err
	}
	defer file.Close()
	
	var documents []Document
	decoder := json.NewDecoder(file)
	if err := decoder.Decode(&documents); err != nil {
		return err
	}
	
	se.db.mu.Lock()
	se.db.documents = documents
	se.db.mu.Unlock()
	
	return nil
}

func main() {
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		fmt.Println("Please set OPENAI_API_KEY environment variable")
		return
	}
	
	// Create search engine
	engine := NewSemanticSearchEngine(apiKey)
	
	// Index some documents
	documents := []struct {
		ID      string
		Title   string
		Content string
	}{
		{
			ID:      "1",
			Title:   "Introduction to Go",
			Content: "Go is a statically typed, compiled programming language designed at Google.",
		},
		{
			ID:      "2",
			Title:   "Concurrency in Go",
			Content: "Go's concurrency primitives make it easy to write concurrent programs.",
		},
		{
			ID:      "3",
			Title:   "Go Garbage Collection",
			Content: "Go has automatic garbage collection that manages memory allocation and release.",
		},
		{
			ID:      "4",
			Title:   "Python Programming",
			Content: "Python is an interpreted, high-level, general-purpose programming language.",
		},
		{
			ID:      "5",
			Title:   "Machine Learning",
			Content: "Machine learning is a method of data analysis that automates analytical model building.",
		},
	}
	
	fmt.Println("Indexing documents...")
	for _, doc := range documents {
		if err := engine.IndexDocument(doc.ID, doc.Title, doc.Content); err != nil {
			log.Printf("Error indexing document %s: %v", doc.ID, err)
		} else {
			fmt.Printf("Indexed: %s\n", doc.Title)
		}
	}
	
	// Save database
	if err := engine.SaveDatabase("search_db.json"); err != nil {
		log.Printf("Error saving database: %v", err)
	}
	
	// Perform searches
	queries := []string{
		"programming language Google",
		"automatic memory management",
		"data analysis automation",
		"concurrent programming",
	}
	
	fmt.Println("\nPerforming searches...")
	for _, query := range queries {
		fmt.Printf("\nQuery: %s\n", query)
		results, err := engine.Search(query, 3)
		if err != nil {
			log.Printf("Search error: %v", err)
			continue
		}
		
		for i, result := range results {
			fmt.Printf("%d. %s (Similarity: %.2f)\n", i+1, result.Document.Title, result.Similarity)
		}
	}
}
```

### How This Example Works:

1. **Document Indexing**:
   - Takes text documents and generates embeddings using OpenAI's API
   - Stores documents with their embeddings in a vector database
   - Implements caching to avoid regenerating embeddings

2. **Semantic Search**:
   - Converts user queries into embeddings
   - Finds documents with similar embeddings using cosine similarity
   - Returns ranked results by similarity score

3. **Persistence**:
   - Saves and loads the vector database to/from JSON files
   - Maintains thread safety with mutex locks

### Real-World Applications:

1. **Content Recommendation Systems**:
   - Suggest similar articles or products
   - Personalize user experiences

2. **Document Management**:
   - Organize large document collections
   - Find related documents automatically

3. **Customer Support**:
   - Match user queries to relevant help articles
   - Automate ticket routing

4. **Research Tools**:
   - Find similar research papers
   - Discover connections between documents

## Best Practices for Text Embeddings in Go

### 1. Choose the Right Approach
- **API-based**: Best for accuracy and ease of use (OpenAI, Cohere)
- **Local models**: Best for privacy and low latency (ONNX, TensorFlow)
- **Hybrid**: Use APIs for development, local models for production

### 2. Optimize Performance
```go
// Batch embedding generation
func BatchGenerateEmbeddings(texts []string, apiKey string) ([][]float32, error) {
    // Implement batch API calls for efficiency
    // This reduces API calls and improves throughput
}

// Parallel processing
func ParallelIndexing(engine *SemanticSearchEngine, docs []Document) {
    var wg sync.WaitGroup
    for _, doc := range docs {
        wg.Add(1)
        go func(d Document) {
            defer wg.Done()
            engine.IndexDocument(d.ID, d.Title, d.Content)
        }(doc)
    }
    wg.Wait()
}
```

### 3. Handle Errors Gracefully
```go
func SafeEmbeddingGeneration(text, apiKey string) ([]float32, error) {
    embedding, err := GenerateEmbeddingUsingOpenAI(text, apiKey)
    if err != nil {
        log.Printf("Embedding generation failed: %v", err)
        // Fallback to zero embedding or retry logic
        return make([]float32, 1536), nil
    }
    return embedding, nil
}
```

### 4. Monitor and Log
```go
type EmbeddingMetrics struct {
    TotalRequests int
    FailedRequests int
    AverageLatency time.Duration
}

func (m *EmbeddingMetrics) RecordRequest(start time.Time, err error) {
    m.TotalRequests++
    if err != nil {
        m.FailedRequests++
    }
    m.AverageLatency = (m.AverageLatency*time.Duration(m.TotalRequests-1) + time.Since(start)) / 
                      time.Duration(m.TotalRequests)
}
```

## Conclusion

Text embeddings are a powerful tool for adding semantic understanding to Go applications. While Go's NLP ecosystem isn't as mature as Python's, we can effectively leverage:

1. **External APIs** for high-quality embeddings (OpenAI, Cohere)
2. **Pre-trained models** with ONNX or TensorFlow for local processing
3. **Vector databases** for efficient similarity search
4. **Caching and optimization** techniques for performance

The semantic search example demonstrates how to build a complete system that:
- Indexes documents with embeddings
- Performs meaning-based search
- Handles persistence and concurrency
- Provides a foundation for more advanced features

Key takeaways:
1. Start with API-based solutions for simplicity
2. Implement proper error handling and monitoring
3. Use caching to optimize performance
4. Consider privacy and latency requirements
5. Build on top of existing libraries rather than reinventing the wheel

As Go's machine learning ecosystem continues to grow, we can expect more native solutions for text embeddings and NLP tasks. For now, the combination of external APIs and careful implementation provides a robust approach to adding semantic capabilities to Go applications.