

# Text Embeddings in Go: A Comprehensive Guide

!!! abstract "Overview"
    Master text embeddings in Go - numerical representations that capture semantic meaning of text. Learn to generate, store, and search embeddings using external APIs, pre-trained models, and vector databases for building semantic search and NLP applications.

!!! tip "Key Points"
    - Text embeddings convert text into dense vector representations
    - Similar texts have similar vector representations
    - Use external APIs (OpenAI, Cohere) for high-quality embeddings
    - Implement semantic search with cosine similarity
    - Vector databases enable efficient similarity search at scale

## Understanding Text Embeddings

Text embeddings are numerical representations of text data that capture semantic meaning. They transform words, sentences, or documents into dense vectors (arrays of numbers) where similar texts have similar vector representations.

!!! info "Text Embedding Process"
    ```mermaid
    graph LR
        A[Text Input] --> B[Tokenization]
        B --> C[Neural Network Processing]
        C --> D[Vector Representation]
        D --> E[Semantic Understanding]
        style A fill:#999,stroke:#333,stroke-width:2px,color:#000
        style E fill:#999,stroke:#333,stroke-width:2px,color:#000
    ```

### Why Use Text Embeddings?

1. **Semantic Search**: Find documents based on meaning rather than keywords
2. **Similarity Comparison**: Measure how similar two texts are
3. **Classification**: Categorize text based on content
4. **Clustering**: Group similar documents together
5. **Recommendation Systems**: Suggest similar content
6. **Anomaly Detection**: Identify unusual text patterns

### Key Concepts

!!! example "Vector Representation"
    ```go title="vector_representation.go" linenums="1" hl_lines="3-7"
    package main

    import "fmt"

    // Embedding represents a text embedding as a slice of float32 values
    type Embedding []float32

    func (e Embedding) Dimensions() int {
        return len(e)
    }

    func main() {
        // Example embedding with 1536 dimensions (OpenAI's text-embedding-ada-002)
        embedding := make(Embedding, 1536)
        fmt.Printf("Embedding dimensions: %d\n", embedding.Dimensions())
    }
    ```

!!! example "Similarity Metrics"
    ```go title="similarity_metrics.go" linenums="1" hl_lines="8-28"
    package main

    import (
        "fmt"
        "math"
    )

    // Cosine similarity between two embeddings
    func CosineSimilarity(a, b Embedding) float64 {
        if len(a) != len(b) {
            panic("Embeddings must have same dimensions")
        }
        
        var dotProduct, normA, normB float64
        
        for i := range a {
            dotProduct += float64(a[i]) * float64(b[i])
            normA += float64(a[i]) * float64(a[i])
            normB += float64(b[i]) * float64(b[i])
        }
        
        if normA == 0 || normB == 0 {
            return 0
        }
        
        return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
    }

    func main() {
        // Example usage
        embedding1 := make(Embedding, 1536)
        embedding2 := make(Embedding, 1536)
        
        // Fill with sample values
        for i := 0; i < 1536; i++ {
            embedding1[i] = float32(i % 100) / 100.0
            embedding2[i] = float32((i + 50) % 100) / 100.0
        }
        
        similarity := CosineSimilarity(embedding1, embedding2)
        fmt.Printf("Cosine similarity: %.4f\n", similarity)
    }
    ```

## Approaches to Generate Embeddings in Go

### 1. Using External APIs (Recommended)

Services like OpenAI, Cohere, and Hugging Face provide embedding APIs:

!!! example "OpenAI Embedding API"
    ```go title="openai_embedding.go" linenums="1" hl_lines="8-60"
    package main

    import (
        "bytes"
        "encoding/json"
        "fmt"
        "io"
        "net/http"
        "os"
    )

    // OpenAIEmbeddingRequest represents the request to OpenAI's embedding API
    type OpenAIEmbeddingRequest struct {
        Input          string `json:"input"`
        Model          string `json:"model"`
        EncodingFormat string `json:"encoding_format,omitempty"`
    }

    // OpenAIEmbeddingResponse represents the response from OpenAI's embedding API
    type OpenAIEmbeddingResponse struct {
        Data []struct {
            Embedding []float32 `json:"embedding"`
        } `json:"data"`
    }

    // GenerateEmbeddingUsingOpenAI generates an embedding using OpenAI's API
    func GenerateEmbeddingUsingOpenAI(text, apiKey string) ([]float32, error) {
        reqBody := OpenAIEmbeddingRequest{
            Input: text,
            Model: "text-embedding-ada-002",
        }
        
        jsonData, err := json.Marshal(reqBody)
        if err != nil {
            return nil, fmt.Errorf("failed to marshal request: %v", err)
        }
        
        req, err := http.NewRequest("POST", "https://api.openai.com/v1/embeddings", bytes.NewBuffer(jsonData))
        if err != nil {
            return nil, fmt.Errorf("failed to create request: %v", err)
        }
        
        req.Header.Set("Content-Type", "application/json")
        req.Header.Set("Authorization", "Bearer "+apiKey)
        
        client := &http.Client{}
        resp, err := client.Do(req)
        if err != nil {
            return nil, fmt.Errorf("failed to send request: %v", err)
        }
        defer resp.Body.Close()
        
        if resp.StatusCode != http.StatusOK {
            body, _ := io.ReadAll(resp.Body)
            return nil, fmt.Errorf("API request failed with status %d: %s", resp.StatusCode, string(body))
        }
        
        var result OpenAIEmbeddingResponse
        if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
            return nil, fmt.Errorf("failed to decode response: %v", err)
        }
        
        if len(result.Data) == 0 {
            return nil, fmt.Errorf("no embeddings returned")
        }
        
        return result.Data[0].Embedding, nil
    }

    func main() {
        apiKey := os.Getenv("OPENAI_API_KEY")
        if apiKey == "" {
            fmt.Println("Please set OPENAI_API_KEY environment variable")
            return
        }
        
        text := "Go is a statically typed, compiled programming language"
        embedding, err := GenerateEmbeddingUsingOpenAI(text, apiKey)
        if err != nil {
            fmt.Printf("Error generating embedding: %v\n", err)
            return
        }
        
        fmt.Printf("Generated embedding with %d dimensions\n", len(embedding))
        fmt.Printf("First 5 dimensions: %v\n", embedding[:5])
    }
    ```

### 2. Using Pre-trained Models with ONNX

For local processing without API calls:

!!! example "ONNX Model Inference"
    ```go title="onnx_embedding.go" linenums="1" hl_lines="8-30"
    package main

    import (
        "fmt"
        "ort"
    )

    // LoadSentenceTransformer loads a pre-trained sentence transformer model
    func LoadSentenceTransformer(modelPath string) (*ort.Session, error) {
        return ort.NewSession(modelPath, nil)
    }

    // GenerateEmbeddingWithONNX generates embedding using ONNX model
    func GenerateEmbeddingWithONNX(session *ort.Session, text string) ([]float32, error) {
        // Tokenization would happen here (simplified for example)
        // In practice, you'd need a tokenizer compatible with your model
        
        // Create input tensor (simplified)
        inputShape := []int64{1, 1} // Batch size 1, sequence length 1
        inputData := []int32{123}    // Example token ID
        
        inputTensor, err := ort.NewTensor(ort.TensorTypeINT32, inputShape, inputData)
        if err != nil {
            return nil, fmt.Errorf("failed to create input tensor: %v", err)
        }
        defer inputTensor.Release()
        
        // Run inference
        output, err := session.Run(map[string]ort.Value{"input_ids": inputTensor})
        if err != nil {
            return nil, fmt.Errorf("inference failed: %v", err)
        }
        defer output.Release()
        
        // Extract embedding (simplified)
        embeddingTensor := output["last_hidden_state"].(*ort.Tensor)
        embedding := embeddingTensor.GetData().([]float32)
        
        return embedding, nil
    }

    func main() {
        // This example requires the ONNX Runtime for Go and a pre-trained model
        // In practice, you'd download a model like all-MiniLM-L6-v2.onnx
        
        fmt.Println("ONNX-based embedding generation requires additional setup")
        fmt.Println("See: https://github.com/microsoft/onnxruntime")
    }
    ```

### 3. Using Go-specific Libraries

Some Go libraries provide embedding capabilities:

!!! example "GoLearn Text Classification"
    ```go title="golearn_example.go" linenums="1" hl_lines="8-22"
    package main

    import (
        "fmt"
        "github.com/sjwhitworth/golearn/base"
        "github.com/sjwhitworth/golearn/knn"
    )

    // Simple example using golearn for text classification
    // Note: This is a simplified example - real embedding generation would require more setup
    func main() {
        // Load dataset (in practice, you'd use a text dataset)
        rawData, err := base.ParseCSVToInstances("text_data.csv", true)
        if err != nil {
            panic(err)
        }
        
        // Create a kNN classifier
        cls := knn.NewKnnClassifier("euclidean", "linear", 2)
        cls.Fit(rawData)
        
        // Make predictions (simplified)
        fmt.Println("Text classification with golearn")
        fmt.Println("This example requires proper text preprocessing")
    }
    ```

## Real-World Example: Semantic Search Engine

Let's build a complete semantic search system that:
1. Pre-computes embeddings for a document collection
2. Stores embeddings in a vector database
3. Searches for similar documents based on query meaning

!!! example "Semantic Search Engine"
    ```go title="semantic_search.go" linenums="1" hl_lines="8-100"
    package main

    import (
        "encoding/json"
        "fmt"
        "log"
        "math"
        "os"
        "sort"
        "sync"
        "time"
    )

    // Document represents a text document with its embedding
    type Document struct {
        ID        string
        Title     string
        Content   string
        Embedding []float32
        Timestamp time.Time
    }

    // SearchResult represents a search result with similarity score
    type SearchResult struct {
        Document   Document
        Similarity float64
    }

    // VectorDatabase stores and searches embeddings
    type VectorDatabase struct {
        documents []Document
        mu        sync.RWMutex
    }

    func NewVectorDatabase() *VectorDatabase {
        return &VectorDatabase{
            documents: make([]Document, 0),
        }
    }

    // AddDocument adds a document to the database
    func (db *VectorDatabase) AddDocument(doc Document) {
        db.mu.Lock()
        defer db.mu.Unlock()
        db.documents = append(db.documents, doc)
    }

    // Search finds similar documents based on embedding similarity
    func (db *VectorDatabase) Search(queryEmbedding []float32, limit int) []SearchResult {
        db.mu.RLock()
        defer db.mu.RUnlock()
        
        var results []SearchResult
        
        for _, doc := range db.documents {
            similarity := CosineSimilarity(queryEmbedding, doc.Embedding)
            results = append(results, SearchResult{
                Document:   doc,
                Similarity: similarity,
            })
        }
        
        // Sort by similarity (descending)
        sort.Slice(results, func(i, j int) bool {
            return results[i].Similarity > results[j].Similarity
        })
        
        if len(results) > limit {
            results = results[:limit]
        }
        
        return results
    }

    // SemanticSearchEngine handles the complete search workflow
    type SemanticSearchEngine struct {
        db             *VectorDatabase
        apiKey         string
        embeddingCache map[string][]float32
        cacheMu        sync.RWMutex
    }

    func NewSemanticSearchEngine(apiKey string) *SemanticSearchEngine {
        return &SemanticSearchEngine{
            db:             NewVectorDatabase(),
            apiKey:         apiKey,
            embeddingCache: make(map[string][]float32),
        }
    }

    // IndexDocument generates embedding and adds to database
    func (se *SemanticSearchEngine) IndexDocument(id, title, content string) error {
        // Check cache first
        se.cacheMu.RLock()
        if embedding, exists := se.embeddingCache[content]; exists {
            se.cacheMu.RUnlock()
            doc := Document{
                ID:        id,
                Title:     title,
                Content:   content,
                Embedding: embedding,
                Timestamp: time.Now(),
            }
            se.db.AddDocument(doc)
            return nil
        }
        se.cacheMu.RUnlock()
        
        // Generate embedding
        embedding, err := GenerateEmbeddingUsingOpenAI(content, se.apiKey)
        if err != nil {
            return fmt.Errorf("failed to generate embedding: %v", err)
        }
        
        // Cache the embedding
        se.cacheMu.Lock()
        se.embeddingCache[content] = embedding
        se.cacheMu.Unlock()
        
        // Add to database
        doc := Document{
            ID:        id,
            Title:     title,
            Content:   content,
            Embedding: embedding,
            Timestamp: time.Now(),
        }
        se.db.AddDocument(doc)
        
        return nil
    }

    // Search performs semantic search
    func (se *SemanticSearchEngine) Search(query string, limit int) ([]SearchResult, error) {
        // Generate query embedding
        queryEmbedding, err := GenerateEmbeddingUsingOpenAI(query, se.apiKey)
        if err != nil {
            return nil, fmt.Errorf("failed to generate query embedding: %v", err)
        }
        
        // Search database
        return se.db.Search(queryEmbedding, limit), nil
    }

    func main() {
        apiKey := os.Getenv("OPENAI_API_KEY")
        if apiKey == "" {
            fmt.Println("Please set OPENAI_API_KEY environment variable")
            return
        }
        
        // Create search engine
        engine := NewSemanticSearchEngine(apiKey)
        
        // Index some documents
        documents := []struct {
            ID      string
            Title   string
            Content string
        }{
            {
                ID:      "1",
                Title:   "Introduction to Go",
                Content: "Go is a statically typed, compiled programming language designed at Google.",
            },
            {
                ID:      "2",
                Title:   "Concurrency in Go",
                Content: "Go's concurrency primitives make it easy to write concurrent programs.",
            },
            {
                ID:      "3",
                Title:   "Go Garbage Collection",
                Content: "Go has automatic garbage collection that manages memory allocation and release.",
            },
            {
                ID:      "4",
                Title:   "Python Programming",
                Content: "Python is an interpreted, high-level, general-purpose programming language.",
            },
            {
                ID:      "5",
                Title:   "Machine Learning",
                Content: "Machine learning is a method of data analysis that automates analytical model building.",
            },
        }
        
        fmt.Println("Indexing documents...")
        for _, doc := range documents {
            if err := engine.IndexDocument(doc.ID, doc.Title, doc.Content); err != nil {
                log.Printf("Error indexing document %s: %v", doc.ID, err)
            } else {
                fmt.Printf("Indexed: %s\n", doc.Title)
            }
        }
        
        // Perform searches
        queries := []string{
            "programming language Google",
            "automatic memory management",
            "data analysis automation",
            "concurrent programming",
        }
        
        fmt.Println("\nPerforming searches...")
        for _, query := range queries {
            fmt.Printf("\nQuery: %s\n", query)
            results, err := engine.Search(query, 3)
            if err != nil {
                log.Printf("Search error: %v", err)
                continue
            }
            
            for i, result := range results {
                fmt.Printf("%d. %s (Similarity: %.2f)\n", i+1, result.Document.Title, result.Similarity)
            }
        }
    }
    ```

### How This Example Works:

1. **Document Indexing**:
   - Takes text documents and generates embeddings using OpenAI's API
   - Stores documents with their embeddings in a vector database
   - Implements caching to avoid regenerating embeddings

2. **Semantic Search**:
   - Converts user queries into embeddings
   - Finds documents with similar embeddings using cosine similarity
   - Returns ranked results by similarity score

3. **Persistence**:
   - Saves and loads the vector database to/from JSON files
   - Maintains thread safety with mutex locks

### Real-World Applications:

1. **Content Recommendation Systems**:
   - Suggest similar articles or products
   - Personalize user experiences

2. **Document Management**:
   - Organize large document collections
   - Find related documents automatically

3. **Customer Support**:
   - Match user queries to relevant help articles
   - Automate ticket routing

4. **Research Tools**:
   - Find similar research papers
   - Discover connections between documents

## Best Practices for Text Embeddings in Go

### 1. Choose the Right Approach

!!! tip "Approach Selection"
    - **API-based**: Best for accuracy and ease of use (OpenAI, Cohere)
    - **Local models**: Best for privacy and low latency (ONNX, TensorFlow)
    - **Hybrid**: Use APIs for development, local models for production

### 2. Optimize Performance

!!! example "Batch Processing"
    ```go title="batch_processing.go" linenums="1" hl_lines="8-25"
    package main

    import (
        "fmt"
        "sync"
    )

    // Batch embedding generation
    func BatchGenerateEmbeddings(texts []string, apiKey string) ([][]float32, error) {
        // Implement batch API calls for efficiency
        // This reduces API calls and improves throughput
        embeddings := make([][]float32, len(texts))
        
        // In a real implementation, you would make a single API call
        // with all texts instead of individual calls
        for i, text := range texts {
            embedding, err := GenerateEmbeddingUsingOpenAI(text, apiKey)
            if err != nil {
                return nil, fmt.Errorf("failed to generate embedding for text %d: %v", i, err)
            }
            embeddings[i] = embedding
        }
        
        return embeddings, nil
    }

    // Parallel processing
    func ParallelIndexing(engine *SemanticSearchEngine, docs []Document) {
        var wg sync.WaitGroup
        for _, doc := range docs {
            wg.Add(1)
            go func(d Document) {
                defer wg.Done()
                engine.IndexDocument(d.ID, d.Title, d.Content)
            }(doc)
        }
        wg.Wait()
    }
    ```

### 3. Handle Errors Gracefully

!!! warning "Error Handling"
    Always implement proper error handling for embedding generation, especially when using external APIs.

!!! example "Safe Embedding Generation"
    ```go title="safe_embedding.go" linenums="1" hl_lines="8-22"
    package main

    import (
        "fmt"
        "log"
    )

    func SafeEmbeddingGeneration(text, apiKey string) ([]float32, error) {
        embedding, err := GenerateEmbeddingUsingOpenAI(text, apiKey)
        if err != nil {
            log.Printf("Embedding generation failed: %v", err)
            // Fallback to zero embedding or retry logic
            return make([]float32, 1536), nil
        }
        return embedding, nil
    }
    ```

### 4. Monitor and Log

!!! example "Embedding Metrics"
    ```go title="embedding_metrics.go" linenums="1" hl_lines="6-22"
    package main

    import (
        "sync/atomic"
        "time"
    )

    type EmbeddingMetrics struct {
        TotalRequests   int64
        FailedRequests  int64
        AverageLatency  time.Duration
        totalLatency   int64
    }

    func (m *EmbeddingMetrics) RecordRequest(start time.Time, err error) {
        atomic.AddInt64(&m.TotalRequests, 1)
        latency := time.Since(start)
        atomic.AddInt64(&m.totalLatency, latency.Nanoseconds())
        
        // Update average latency
        total := atomic.LoadInt64(&m.TotalRequests)
        totalLat := atomic.LoadInt64(&m.totalLatency)
        m.AverageLatency = time.Duration(totalLat / total)
        
        if err != nil {
            atomic.AddInt64(&m.FailedRequests, 1)
        }
    }
    ```

## Quick Reference

!!! success "Key Takeaways"
    - **Vector Representation**: Text embeddings convert text into dense numerical vectors
    - **Similarity Metrics**: Cosine similarity is the most common way to compare embeddings
    - **API Generation**: Use OpenAI, Cohere, or similar services for high-quality embeddings
    - **Local Processing**: ONNX or TensorFlow for privacy and low latency
    - **Vector Databases**: Store and search embeddings efficiently
    - **Semantic Search**: Find documents by meaning, not just keywords
    - **Performance Optimization**: Batch processing and caching improve efficiency

!!! quote "Remember"
    "Text embeddings in Go provide a bridge between human language and machine understanding. While Go's NLP ecosystem is still evolving, combining external APIs with careful implementation allows you to build powerful semantic applications. Focus on proper error handling, performance optimization, and user experience to create effective text-based solutions."