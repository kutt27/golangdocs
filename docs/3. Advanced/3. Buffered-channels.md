# Buffered Channels in Go: A Comprehensive Guide

!!! abstract "Overview"
    Master Go's buffered channels for asynchronous communication between goroutines. Learn how buffered channels decouple senders and receivers, enabling more flexible concurrent designs. Understand the buffering mechanism, capacity management, and when to use buffered channels versus unbuffered ones. Explore patterns like rate limiting, batching, and worker pools that leverage buffered channels for efficient concurrent processing.

!!! tip "Key Points"
    - Buffered channels have a specified capacity, allowing them to hold multiple values before blocking
    - Send operations block only when the buffer is full; receive operations block only when the buffer is empty
    - Buffered channels provide asynchronous communication, decoupling sender and receiver goroutines
    - They're ideal for rate limiting, batching operations, and managing work queues
    - The buffer size affects performance and concurrency characteristics
    - Proper sizing is crucial to avoid deadlocks and excessive memory usage
    - Buffered channels can be used with all channel operations (send, receive, close, range, select)
    - They form the foundation for many advanced concurrency patterns in Go

## Understanding Buffered Channels

Buffered channels in Go are channels with a specified capacity that can hold multiple values before blocking. Unlike unbuffered channels that require both sender and receiver to be ready simultaneously, buffered channels allow senders to proceed until the buffer is full and receivers to proceed until the buffer is empty.

!!! info "Buffered Channel Architecture"
    ```mermaid
    graph TB
        A[Goroutine 1] -->|Send| B[Buffered Channel]
        B -->|Receive| C[Goroutine 2]
        D[Buffer] --> B
        E[Go Runtime] --> B
        F[Memory] --> B
        style A fill:#ccf,stroke:#333,stroke-width:2px,color:#000
        style C fill:#ccf,stroke:#333,stroke-width:2px,color:#000
        style B fill:#f9f,stroke:#333,stroke-width:2px,color:#000
        style D fill:#9cf,stroke:#333,stroke-width:2px,color:#000
    ```

Key characteristics of buffered channels:
- **Capacity**: The number of values the channel can hold before blocking
- **Asynchronous**: Senders and receivers don't need to synchronize directly
- **Queue Behavior**: Values are received in the order they were sent (FIFO)
- **Blocking Conditions**: Send blocks when buffer is full; receive blocks when buffer is empty

## Creating Buffered Channels

Buffered channels are created using the `make` function with a capacity argument:

!!! example "Creating Buffered Channels"
    ```go title="creating_buffered.go" linenums="1" hl_lines="8-24"
    package main

    import "fmt"

    func main() {
        // Create a buffered channel with capacity 3
        ch := make(chan int, 3)
        
        fmt.Printf("Channel type: %T\n", ch)
        fmt.Printf("Channel capacity: %d\n", cap(ch))
        fmt.Printf("Channel length (initial): %d\n", len(ch))
        
        // Send values without blocking
        ch <- 1
        ch <- 2
        ch <- 3
        
        fmt.Printf("Channel length (after sends): %d\n", len(ch))
        
        // Receive values
        fmt.Println(<-ch)
        fmt.Println(<-ch)
        fmt.Println(<-ch)
        
        fmt.Printf("Channel length (after receives): %d\n", len(ch))
    }
    ```

!!! example "Different Buffer Sizes"
    ```go title="buffer_sizes.go" linenums="1" hl_lines="8-32"
    package main

    import (
        "fmt"
        "time"
    )

    func main() {
        // Channel with capacity 1
        ch1 := make(chan string, 1)
        ch1 <- "Hello"
        fmt.Println("Sent to ch1")
        
        // Channel with capacity 5
        ch5 := make(chan string, 5)
        for i := 0; i < 5; i++ {
            ch5 <- fmt.Sprintf("Message %d", i)
        }
        fmt.Printf("Sent 5 messages to ch5, length: %d\n", len(ch5))
        
        // Channel with large capacity
        largeCh := make(chan int, 100)
        for i := 0; i < 100; i++ {
            largeCh <- i
        }
        fmt.Printf("Sent 100 integers to largeCh, length: %d\n", len(largeCh))
        
        // Demonstrate non-blocking sends when buffer has space
        ch := make(chan int, 2)
        ch <- 1
        ch <- 2
        fmt.Println("Sent 2 values without blocking")
        
        // This would block because buffer is full
        // ch <- 3 // This line would block
    }
    ```

## Buffering Mechanism

The Go runtime implements buffered channels as a fixed-size circular buffer. When a value is sent to a buffered channel, it's placed at the end of the buffer if there's space. When a value is received, it's taken from the beginning of the buffer.

!!! example "Buffering Mechanism Demo"
    ```go title="buffering_mechanism.go" linenums="1" hl_lines="8-42"
    package main

    import (
        "fmt"
        "time"
    )

    func main() {
        // Create a buffered channel with capacity 3
        ch := make(chan int, 3)
        
        // Sender goroutine
        go func() {
            for i := 1; i <= 5; i++ {
                fmt.Printf("Sending %d (buffer length: %d)\n", i, len(ch))
                ch <- i
                fmt.Printf("Sent %d (buffer length: %d)\n", i, len(ch))
                time.Sleep(100 * time.Millisecond)
            }
            close(ch)
        }()
        
        // Receiver goroutine
        go func() {
            time.Sleep(350 * time.Millisecond) // Let buffer fill up
            for i := 1; i <= 5; i++ {
                time.Sleep(150 * time.Millisecond) // Receive slower than send
                val := <-ch
                fmt.Printf("Received %d (buffer length: %d)\n", val, len(ch))
            }
        }()
        
        // Wait for communication to complete
        time.Sleep(2 * time.Second)
    }
    ```

## Blocking Behavior

Understanding when buffered channels block is crucial for writing correct concurrent code:

1. **Send Operations**:
   - Block only when the buffer is full
   - Unblock when a receiver takes a value from the buffer

2. **Receive Operations**:
   - Block only when the buffer is empty
   - Unblock when a sender adds a value to the buffer

3. **Closing Channels**:
   - Closing a buffered channel doesn't block
   - Receivers can still get values from the buffer after it's closed
   - Receive operations on a closed buffered channel return zero values when buffer is empty

!!! example "Blocking Behavior Demo"
    ```go title="blocking_behavior.go" linenums="1" hl_lines="8-46"
    package main

    import (
        "fmt"
        "time"
    )

    func sender(ch chan<- int, id int) {
        for i := 1; i <= 3; i++ {
            fmt.Printf("Sender %d: Sending %d\n", id, i)
            ch <- i
            fmt.Printf("Sender %d: Sent %d\n", id, i)
            time.Sleep(100 * time.Millisecond)
        }
    }

    func receiver(ch <-chan int, id int) {
        for i := 1; i <= 3; i++ {
            time.Sleep(200 * time.Millisecond) // Receive slower than send
            val := <-ch
            fmt.Printf("Receiver %d: Received %d\n", id, val)
        }
    }

    func main() {
        // Create a buffered channel with capacity 2
        ch := make(chan int, 2)
        
        // Start two senders and one receiver
        go sender(ch, 1)
        go sender(ch, 2)
        go receiver(ch, 1)
        
        // Wait for communication to complete
        time.Sleep(2 * time.Second)
        fmt.Println("Communication completed")
    }
    ```

## Use Cases for Buffered Channels

### 1. Rate Limiting

Buffered channels are excellent for implementing rate limiters:

!!! example "Rate Limiting"
    ```go title="rate_limiting.go" linenums="1" hl_lines="8-38"
    package main

    import (
        "fmt"
        "time"
    )

    func worker(id int, jobs <-chan int, results chan<- int) {
        for j := range jobs {
            fmt.Printf("Worker %d processing job %d\n", id, j)
            time.Sleep(time.Second) // Simulate work
            results <- j * 2
        }
    }

    func main() {
        // Create a buffered channel for rate limiting (max 3 concurrent jobs)
        jobs := make(chan int, 3)
        results := make(chan int, 10)
        
        // Start 3 workers
        for w := 1; w <= 3; w++ {
            go worker(w, jobs, results)
        }
        
        // Send 5 jobs with rate limiting
        for j := 1; j <= 5; j++ {
            jobs <- j
            fmt.Printf("Sent job %d (buffer length: %d)\n", j, len(jobs))
        }
        close(jobs)
        
        // Collect results
        for a := 1; a <= 5; a++ {
            result := <-results
            fmt.Printf("Received result %d\n", result)
        }
    }
    ```

### 2. Batching Operations

Buffered channels can be used to batch operations for efficiency:

!!! example "Batching Operations"
    ```go title="batching.go" linenums="1" hl_lines="8-52"
    package main

    import (
        "fmt"
        "time"
    )

    func batchProcessor(input <-chan int, output chan<- []int, batchSize int) {
        batch := make([]int, 0, batchSize)
        
        for {
            select {
            case val, ok := <-input:
                if !ok {
                    // Input channel closed, send remaining batch
                    if len(batch) > 0 {
                        output <- batch
                    }
                    close(output)
                    return
                }
                
                batch = append(batch, val)
                if len(batch) >= batchSize {
                    output <- batch
                    batch = batch[:0] // Reset batch
                }
                
            case <-time.After(100 * time.Millisecond):
                // Timeout, send partial batch
                if len(batch) > 0 {
                    output <- batch
                    batch = batch[:0]
                }
            }
        }
    }

    func main() {
        input := make(chan int)
        output := make(chan []int)
        
        // Start batch processor
        go batchProcessor(input, output, 3)
        
        // Send input values
        go func() {
            for i := 1; i <= 10; i++ {
                input <- i
                time.Sleep(50 * time.Millisecond)
            }
            close(input)
        }()
        
        // Process batches
        for batch := range output {
            fmt.Printf("Processing batch: %v\n", batch)
            time.Sleep(200 * time.Millisecond) // Simulate processing
        }
        
        fmt.Println("All batches processed")
    }
    ```

### 3. Work Queue

Buffered channels are perfect for implementing work queues:

!!! example "Work Queue"
    ```go title="work_queue.go" linenums="1" hl_lines="8-54"
    package main

    import (
        "fmt"
        "math/rand"
        "sync"
        "time"
    )

    type Task struct {
        ID   int
        Data string
    }

    func worker(id int, tasks <-chan Task, wg *sync.WaitGroup) {
        defer wg.Done()
        
        for task := range tasks {
            fmt.Printf("Worker %d started task %d\n", id, task.ID)
            
            // Simulate work with random duration
            workTime := time.Duration(100+rand.Intn(200)) * time.Millisecond
            time.Sleep(workTime)
            
            fmt.Printf("Worker %d completed task %d\n", id, task.ID)
        }
        
        fmt.Printf("Worker %d shutting down\n", id)
    }

    func main() {
        // Seed random number generator
        rand.Seed(time.Now().UnixNano())
        
        // Create a buffered channel for tasks (queue capacity 10)
        tasks := make(chan Task, 10)
        var wg sync.WaitGroup
        
        // Start 3 workers
        const numWorkers = 3
        for i := 1; i <= numWorkers; i++ {
            wg.Add(1)
            go worker(i, tasks, &wg)
        }
        
        // Generate and enqueue tasks
        const numTasks = 15
        for i := 1; i <= numTasks; i++ {
            task := Task{
                ID:   i,
                Data: fmt.Sprintf("Task-%d", i),
            }
            tasks <- task
            fmt.Printf("Enqueued task %d (queue length: %d)\n", i, len(tasks))
            
            // Small delay between task generation
            time.Sleep(50 * time.Millisecond)
        }
        
        // Close tasks channel when all tasks are enqueued
        close(tasks)
        fmt.Println("All tasks enqueued, waiting for workers to complete")
        
        // Wait for all workers to finish
        wg.Wait()
        fmt.Println("All tasks completed")
    }
    ```

## Select with Buffered Channels

The `select` statement works seamlessly with buffered channels, enabling non-blocking operations and timeouts:

!!! example "Select with Buffered Channels"
    ```go title="select_buffered.go" linenums="1" hl_lines="8-46"
    package main

    import (
        "fmt"
        "time"
    )

    func main() {
        ch1 := make(chan string, 2)
        ch2 := make(chan string, 2)
        
        // Pre-fill channels
        ch1 <- "Message 1 from ch1"
        ch1 <- "Message 2 from ch1"
        ch2 <- "Message 1 from ch2"
        
        // Use select to process messages
        for i := 0; i < 3; i++ {
            select {
            case msg := <-ch1:
                fmt.Printf("Received from ch1: %s\n", msg)
            case msg := <-ch2:
                fmt.Printf("Received from ch2: %s\n", msg)
            case <-time.After(100 * time.Millisecond):
                fmt.Println("Timeout!")
                break
            }
        }
        
        // Demonstrate non-blocking send
        ch3 := make(chan int, 1)
        ch3 <- 42 // Buffer is now full
        
        select {
        case ch3 <- 43: // This would block
            fmt.Println("Sent to ch3")
        default:
            fmt.Println("Could not send to ch3, buffer full")
        }
        
        // Receive to make space
        <-ch3
        
        // Now non-blocking send should work
        select {
        case ch3 <- 43:
            fmt.Println("Successfully sent to ch3")
        default:
            fmt.Println("Could not send to ch3")
        }
    }
    ```

## Common Patterns

### 1. Fan-out with Buffered Channels

!!! example "Fan-out Pattern"
    ```go title="fan_out_buffered.go" linenums="1" hl_lines="8-54"
    package main

    import (
        "fmt"
        "sync"
        "time"
    )

    func worker(id int, jobs <-chan int, results chan<- int, wg *sync.WaitGroup) {
        defer wg.Done()
        
        for job := range jobs {
            fmt.Printf("Worker %d processing job %d\n", id, job)
            time.Sleep(time.Duration(job%3+1) * 100 * time.Millisecond)
            results <- job * 2
        }
    }

    func main() {
        // Create buffered channels
        jobs := make(chan int, 10) // Buffer jobs to prevent blocking
        results := make(chan int, 20)
        
        var wg sync.WaitGroup
        
        // Start 4 workers
        const numWorkers = 4
        for i := 1; i <= numWorkers; i++ {
            wg.Add(1)
            go worker(i, jobs, results, &wg)
        }
        
        // Start a goroutine to close results when workers are done
        go func() {
            wg.Wait()
            close(results)
        }()
        
        // Send jobs
        const numJobs = 20
        for j := 1; j <= numJobs; j++ {
            jobs <- j
            if j%5 == 0 {
                fmt.Printf("Sent %d jobs, buffer length: %d\n", j, len(jobs))
            }
        }
        close(jobs)
        
        // Collect results
        completed := 0
        for result := range results {
            completed++
            if completed%5 == 0 {
                fmt.Printf("Processed %d results\n", completed)
            }
            _ = result // Ignore result for this example
        }
        
        fmt.Printf("All %d jobs processed\n", numJobs)
    }
    ```

### 2. Resource Pool with Buffered Channels

!!! example "Resource Pool"
    ```go title="resource_pool.go" linenums="1" hl_lines="8-60"
    package main

    import (
        "fmt"
        "sync"
        "time"
    )

    // Resource represents a shared resource
    type Resource struct {
        ID int
    }

    // ResourcePool manages a pool of resources
    type ResourcePool struct {
        resources chan *Resource
        wg        sync.WaitGroup
    }

    func NewResourcePool(size int) *ResourcePool {
        pool := &ResourcePool{
            resources: make(chan *Resource, size),
        }
        
        // Initialize resources
        for i := 1; i <= size; i++ {
            pool.resources <- &Resource{ID: i}
        }
        
        return pool
    }

    func (p *ResourcePool) Get() *Resource {
        return <-p.resources
    }

    func (p *ResourcePool) Put(resource *Resource) {
        p.resources <- resource
    }

    func (p *ResourcePool) Close() {
        close(p.resources)
    }

    func worker(id int, pool *ResourcePool) {
        defer pool.wg.Done()
        
        for i := 1; i <= 3; i++ {
            // Acquire resource
            resource := pool.Get()
            fmt.Printf("Worker %d acquired resource %d\n", id, resource.ID)
            
            // Simulate work
            time.Sleep(time.Duration(100+id*50) * time.Millisecond)
            
            // Release resource
            pool.Put(resource)
            fmt.Printf("Worker %d released resource %d\n", id, resource.ID)
        }
    }

    func main() {
        // Create a resource pool with 3 resources
        pool := NewResourcePool(3)
        defer pool.Close()
        
        // Start 5 workers competing for resources
        const numWorkers = 5
        for i := 1; i <= numWorkers; i++ {
            pool.wg.Add(1)
            go worker(i, pool)
        }
        
        pool.wg.Wait()
        fmt.Println("All workers completed")
    }
    ```

## Best Practices

!!! tip "Choose Appropriate Buffer Size"
    The buffer size significantly affects performance and behavior.

!!! example "Buffer Sizing"
    ```go title="buffer_sizing.go" linenums="1" hl_lines="8-30"
    package main

    import (
        "fmt"
        "runtime"
        "time"
    )

    func worker(id int, jobs <-chan int, results chan<- int) {
        for j := range jobs {
            fmt.Printf("Worker %d started job %d\n", id, j)
            time.Sleep(100 * time.Millisecond)
            results <- j * 2
            fmt.Printf("Worker %d finished job %d\n", id, j)
        }
    }

    func main() {
        numCPU := runtime.NumCPU()
        fmt.Printf("Running on %d CPUs\n", numCPU)
        
        // Buffer size = number of workers (good balance)
        jobs := make(chan int, numCPU)
        results := make(chan int, numCPU*2)
        
        // Start workers
        for w := 1; w <= numCPU; w++ {
            go worker(w, jobs, results)
        }
        
        // Send jobs
        for j := 1; j <= 10; j++ {
            jobs <- j
        }
        close(jobs)
        
        // Collect results
        for a := 1; a <= 10; a++ {
            <-results
        }
    }
    ```

!!! tip "Prevent Goroutine Leaks"
    Always ensure buffered channels are properly closed to prevent goroutine leaks.

!!! example "Preventing Leaks"
    ```go title="preventing_leaks.go" linenums="1" hl_lines="8-32"
    package main

    import (
        "fmt"
        "time"
    )

    func processValues(values []int, out chan<- int) {
        defer close(out) // Ensure channel is closed
        
        for _, v := range values {
            out <- v * 2
        }
    }

    func main() {
        values := []int{1, 2, 3, 4, 5}
        out := make(chan int, len(values)) // Buffer size matches input
        
        go processValues(values, out)
        
        // Process all values
        for result := range out {
            fmt.Println("Processed:", result)
        }
        
        fmt.Println("All values processed")
    }
    ```

!!! tip "Handle Full Buffers Gracefully"
    Use select with default to handle cases where buffer is full.

!!! example "Graceful Full Buffer Handling"
    ```go title="graceful_full_buffer.go" linenums="1" hl_lines="8-34"
    package main

    import (
        "fmt"
        "time"
    )

    func sender(ch chan<- int, values []int) {
        for _, v := range values {
            select {
            case ch <- v:
                fmt.Printf("Sent %d\n", v)
            default:
                fmt.Printf("Buffer full, dropping value %d\n", v)
            }
            time.Sleep(100 * time.Millisecond)
        }
    }

    func main() {
        ch := make(chan int, 2) // Small buffer
        
        // Slow receiver
        go func() {
            time.Sleep(500 * time.Millisecond)
            for i := 0; i < 3; i++ {
                val := <-ch
                fmt.Printf("Received %d\n", val)
                time.Sleep(200 * time.Millisecond)
            }
        }()
        
        // Fast sender
        values := []int{1, 2, 3, 4, 5, 6}
        sender(ch, values)
        
        time.Sleep(2 * time.Second)
        fmt.Println("Communication completed")
    }
    ```

!!! tip "Monitor Buffer Usage"
    Track buffer length to understand system behavior and tune performance.

!!! example "Buffer Monitoring"
    ```go title="buffer_monitoring.go" linenums="1" hl_lines="8-44"
    package main

    import (
        "fmt"
        "time"
    )

    func monitor(ch chan int, done chan struct{}) {
        ticker := time.NewTicker(100 * time.Millisecond)
        defer ticker.Stop()
        
        for {
            select {
            case <-ticker.C:
                fmt.Printf("Buffer usage: %d/%d\n", len(ch), cap(ch))
            case <-done:
                fmt.Println("Monitor stopped")
                return
            }
        }
    }

    func main() {
        ch := make(chan int, 5)
        done := make(chan struct{})
        
        // Start monitor
        go monitor(ch, done)
        
        // Send values
        go func() {
            for i := 1; i <= 10; i++ {
                ch <- i
                time.Sleep(50 * time.Millisecond)
            }
            close(ch)
        }()
        
        // Receive values
        go func() {
            time.Sleep(300 * time.Millisecond) // Let buffer fill
            for range ch {
                time.Sleep(100 * time.Millisecond)
            }
            close(done)
        }()
        
        <-done
        fmt.Println("Communication completed")
    }
    ```

## Real-World Example: Concurrent Web Crawler with Rate Limiting

Let's create a comprehensive example that demonstrates buffered channels in a web crawling context:

!!! example "Web Crawler with Rate Limiting"
    ```go title="web_crawler.go" linenums="1" hl_lines="8-114"
    package main

    import (
        "fmt"
        "io"
        "net/http"
        "sync"
        "time"
    )

    // Result represents a crawled page
    type Result struct {
        URL   string
        Size  int
        Error error
    }

    // Crawler represents a web crawler
    type Crawler struct {
        client       *http.Client
        maxConcurrent int
        rateLimit    time.Duration
    }

    func NewCrawler(maxConcurrent int, rateLimit time.Duration) *Crawler {
        return &Crawler{
            client: &http.Client{
                Timeout: 5 * time.Second,
            },
            maxConcurrent: maxConcurrent,
            rateLimit:    rateLimit,
        }
    }

    func (c *Crawler) fetch(url string, results chan<- Result, tokens chan struct{}, wg *sync.WaitGroup) {
        defer wg.Done()
        
        // Acquire token (rate limiting)
        tokens <- struct{}{}
        defer func() { <-tokens }()
        
        resp, err := c.client.Get(url)
        if err != nil {
            results <- Result{URL: url, Error: err}
            return
        }
        defer resp.Body.Close()
        
        if resp.StatusCode != http.StatusOK {
            results <- Result{URL: url, Error: fmt.Errorf("HTTP %d", resp.StatusCode)}
            return
        }
        
        body, err := io.ReadAll(resp.Body)
        if err != nil {
            results <- Result{URL: url, Error: err}
            return
        }
        
        results <- Result{
            URL:  url,
            Size: len(body),
        }
    }

    func (c *Crawler) Crawl(urls []string) []Result {
        // Create channels
        tokens := make(chan struct{}, c.maxConcurrent) // Rate limiting tokens
        results := make(chan Result, len(urls))        // Buffer for results
        
        var wg sync.WaitGroup
        
        // Start fetcher goroutines
        for _, url := range urls {
            wg.Add(1)
            go c.fetch(url, results, tokens, &wg)
        }
        
        // Start a goroutine to close results when all fetchers are done
        go func() {
            wg.Wait()
            close(results)
        }()
        
        // Collect results
        var allResults []Result
        for result := range results {
            allResults = append(allResults, result)
        }
        
        return allResults
    }

    func main() {
        // URLs to crawl
        urls := []string{
            "https://example.com",
            "https://golang.org",
            "https://github.com",
            "https://stackoverflow.com",
            "https://go.dev",
            "https://pkg.go.dev",
            "https://blog.golang.org",
            "https://tour.golang.org",
            "https://play.golang.org",
            "https://golang.google.cn",
        }
        
        // Create crawler with rate limiting
        crawler := NewCrawler(3, 200*time.Millisecond)
        
        fmt.Println("Starting web crawl...")
        start := time.Now()
        
        results := crawler.Crawl(urls)
        
        duration := time.Since(start)
        fmt.Printf("Crawl completed in %v\n", duration)
        
        // Print results
        var totalSize int
        var errorCount int
        
        for _, result := range results {
            if result.Error != nil {
                fmt.Printf("ERROR %s: %v\n", result.URL, result.Error)
                errorCount++
            } else {
                fmt.Printf("OK %s: %d bytes\n", result.URL, result.Size)
                totalSize += result.Size
            }
        }
        
        // Print summary
        fmt.Printf("\nSummary:\n")
        fmt.Printf("Total URLs: %d\n", len(urls))
        fmt.Printf("Successful: %d\n", len(urls)-errorCount)
        fmt.Printf("Failed: %d\n", errorCount)
        fmt.Printf("Total bytes: %d\n", totalSize)
        fmt.Printf("Average time per URL: %v\n", duration/time.Duration(len(urls)))
    }
    ```

### How This Example Demonstrates Buffered Channel Concepts:

1. **Rate Limiting**:
   - Tokens channel with limited capacity controls concurrent requests
   - Acquiring and releasing tokens enforces rate limiting

2. **Result Collection**:
   - Buffered results channel collects output from all fetchers
   - Buffer size matches number of URLs for efficient collection

3. **Concurrency Control**:
   - Fixed number of tokens limits concurrent goroutines
   - Prevents overwhelming the server or network

4. **Error Handling**:
   - Errors are propagated through the results channel
   - Both successful and failed results are collected

5. **Performance Monitoring**:
   - Timing measurements show the effect of rate limiting
   - Buffer usage is implicit in the token acquisition pattern

## Quick Reference

!!! success "Key Takeaways"
    - **Buffered Channels**: Have capacity to hold multiple values, enabling asynchronous communication
    - **Blocking Behavior**: Send blocks when buffer is full; receive blocks when buffer is empty
    - **Buffer Sizing**: Choose capacity based on use case - too small causes blocking, too large wastes memory
    - **Rate Limiting**: Buffered channels are ideal for controlling operation rates
    - **Batching**: Use buffered channels to collect and process data in batches
    - **Work Queues**: Buffered channels naturally implement work queues with backpressure
    - **Resource Pools**: Manage shared resources with buffered channels
    - **Select Integration**: Buffered channels work seamlessly with select for non-blocking operations
    - **Leak Prevention**: Always close channels when done to prevent goroutine leaks
    - **Performance**: Monitor buffer usage to tune and optimize concurrent systems

!!! quote "Remember"
    "Buffered channels provide a powerful abstraction for asynchronous communication in Go, enabling more flexible and efficient concurrent designs than unbuffered channels alone. By understanding their buffering mechanism, blocking behavior, and appropriate use cases, you can build sophisticated concurrent systems that handle backpressure, rate limiting, and resource management effectively. The key is to choose the right buffer size for your specific needs and to always handle channel operations with care to avoid deadlocks and leaks."